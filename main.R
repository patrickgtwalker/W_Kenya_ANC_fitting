## This is a [insert name of what this is] which summarises the key features of our approach outlined in /final_name_analysis to assessing the relationship between prevalence of malaria within antenatal care relative to that in the community in Rarieda sub-county in Western Kenya
## we will first show how we fit and compare models of differing complexity then how we generate out-of-sample predictions for settings based on ANC prevalence alone and quantfy the incremental value of the data compared to infromation typically available via population based surveys of malaria prevalnce in the community

source("setup.R")
source("functions.R")
source("data_generation.R")
source("models.R")
source("plot_functions.R")
set.seed(100)

## generate synthetic data representing most simple and complex model
## model 1 - simplest:
## prevalence varying by site and month, constant log-odds diff ANC vs community
m1_data<-generate_data_m1()
get_data_plots(m1_data$data_to_model)
## model 5 - most complex:
##prevalence varying by site and month, linear relationship on logit-scale with different slopes and intercepts depending upon gravidity category
m5_data<-generate_data_m5()
get_data_plots(m5_data$data_to_model)
### fit models
m1_fitting<-fit_m1(m1_data$data_to_model,1000,1000,10)
m5_fitting<-fit_m5(m5_data$data_to_model,1000,2000,10)

### check model recaptures parameters 
m1_plots<-get_fit_plots(m1_fitting,m1_data$simulated_survey_data,m1_data$param_df)
m1_plots
m5_plots<-get_fit_plots(m5_fitting,m5_data$simulated_survey_data,m5_data$param_df)
m5_plots


## fit the simplest model to data generated by the most complex to highlight fitting metrics
m1_fit_to_m5_data<-fit_m1(m5_data$data_to_model,1000,2000,1)

### can see visually a worse fit (NB parameter fit and simulated values should be different)
m1_fit_m5_data_plots<-get_fit_plots(m1_fit_to_m5_data,m5_data$simulated_survey_data,m5_data$param_df)
m1_fit_m5_data_plots
### model 5 has approx 6 more effective params..
m5_fitting$p_d-m1_fit_to_m5_data$p_d

### but still gives better fit adjusting for over-fitting via DIC 
m5_fitting$DIC-m1_fit_to_m5_data$DIC

### now we want to assess the extent to which models can predict out-of-sample
### here an example where we want to see how well we can reconstruct ANC prevalence between surveys of a few months spaced every few years
### let's relax the assumption month-specific ORs are normally distributed
months_to_predict<-generate_data_m1_runif_month()

### predict_months_m1() now uses model 1 above but using a fixed effect (rather than normally-distributed random) for month to give maximum flexibility to the prediction by month
predict_months<-predict_months_m1(months_to_predict$data_to_model,500,1000,5)

### predicts well visually (as we'd expect given the data and predictions are generated using the same model)
predict_months_plot<-get_fit_plots(predict_months,months_to_predict$simulated_survey_data,months_to_predict$param_df,pred_months=months_to_predict$pred_months)
predict_months_plot$overall_plot

## similarly with non-normal site-specific ORs....
sites_to_predict<-generate_data_m1_runif_site()
predict_sites<-predict_sites_m1(sites_to_predict$data_to_model,100,200,1)

### again predicts well visually in this dummy situation where we're fitting the same model used to generate the data
predict_sites_plot<-get_fit_plots(predict_sites,sites_to_predict$simulated_survey_data,sites_to_predict$param_df,pred_sites=sites_to_predict$pred_sites)
predict_sites_plot$overall_plot

##...but how do we assess quantitatively? In our analysis we present two metrics - Residual Mean Square Error (RMSE) in the absolute difference between % prevalence in our predictions vs the observed prevalence and the Continuous Ranked Probability score
### RMSE is much easier to understand and more representative of a distant metric likely to be a measure of how many more/fewer people you are likely to find infected in a sample, but penalising more for predictions that are further away
predict_months_plot$prediction_metrics%>%
  filter(month!="all",site!="all")%>%
  summarise(mean_pc_RMSE=mean(RMSE*100))
predict_months_plot$prediction_metrics%>%
  filter(site=="all")%>%
  summarise(mean_pc_RMSE_over_sites=mean(RMSE*100))


### but RMSE has many disadvantages and typically isn't recommended for assessment validity of a probablity metric (e.g. if for a situation with 50% predictions of 47%-53% may reasonable, for a setting with 1% prevalence predictions of -2% and 4% are likely to be substantially less useful, yet all four of these predictions have same RMSE)
### CRPS - a [give relevant layperson definition of CRPS] is much more technically valid but is far less intuitive here we can view it as [tell me what I can view it as]
CPRS_month_site<-predict_months_plot$prediction_metrics%>%
  filter(month!="all",site!="all")%>%
  summarise(mean_pc_CRPS=mean(CRPS*100))
CPRS_month_site
CPRS_month<-predict_months_plot$prediction_metrics%>%
  filter(site=="all")%>%
  summarise(mean_pc_CRPS_over_sites=mean(CRPS*100))
CPRS_month

## However, a clear question arises 'what is the ANC data actually adding to what we currently have??'
## for this we need to define a 'null model' for what we would normally predict in the absence of the data
## the choice of this is somewhat subjective but in our analysis we compare predictions made using ANC data alone with those where we extrapolate from most recent survey data supplied for model fitting (here we use an example akin to a likely gap between survey of three years, in our analysis we provide ANC data a higher benchmark of being superior in predicting over the next five months following a continuous survey) 
months_to_predict_no_ANC<-months_to_predict
months_to_predict_no_ANC$data_to_model<-months_to_predict$data_to_model%>%filter(ANC==0)
predict_month_no_ANC<-predict_nearest_month(months_to_predict_no_ANC$data_to_model,500,1000,5)
predict_month_no_ANC_plot<-get_fit_plots(predict_month_no_ANC,months_to_predict_no_ANC$simulated_survey_data,months_to_predict_no_ANC$param_df,pred_months=months_to_predict_no_ANC$pred_months)

## in this dummy example this approach will work particularly badly as monthly ORs are completely random whereas in reality community prevalence is likley to be subject to a high degree of autocorrelation
predict_month_no_ANC_plot$overall_plot

### we can now calculate the CPRS of this 'null' model where we rely purely on the survey data involved in training the model

CPRS_month_null<-predict_month_no_ANC_plot$prediction_metrics%>%
  filter(site=="all")%>%
  summarise(mean_pc_CRPS_over_sites=mean(CRPS*100))

## A useful summary is the relative CRPS 'Skill' (CRPSS) of the model which [give intuitive definition] here a value of 93% represents [give intuitve definition]
(1-CPRS_month$mean_pc_CRPS_over_sites/CPRS_month_null$mean_pc_CRPS_over_sites)*100


### for locations-specific data we use a null model whereby the prevalence in a given location without ANC is modeled by extrapolating from a simple random-effects model for the other locations in the region
sites_to_predict_no_ANC<-sites_to_predict
sites_to_predict_no_ANC$data_to_model<-sites_to_predict$data_to_model%>%filter(ANC==0)
predict_sites_no_ANC<-predict_RE_site(sites_to_predict_no_ANC$data_to_model,500,1000,5)
predict_sites_no_ANC_plot<-get_fit_plots(predict_sites_no_ANC,sites_to_predict_no_ANC$simulated_survey_data,sites_to_predict_no_ANC$param_df,pred_sites=sites_to_predict_no_ANC$pred_months)

### As site-specific prevalence is U(0,1) distributed this will perform poorly in our dummy example
predict_sites_no_ANC_plot<-get_fit_plots(predict_sites_no_ANC,sites_to_predict_no_ANC$simulated_survey_data,sites_to_predict_no_ANC$param_df,pred_sites=sites_to_predict_no_ANC$pred_sites)

##### However, in our analysis this would provide much more context-specific information compared to relying upon a typical MIS - our null model involves extrapolate from data from x thousand samples from a population of y sampled from all villages outside of the sub-location. In contrast the most recent Kenya MIS has data from x children to represent a population of y million in the Lake region of the country.

## we can quantify the incremental value using CPRSS as with the monthly-predictions
CPRS_site_null<-predict_sites_no_ANC_plot$prediction_metrics%>%
  filter(site=="all")%>%
  summarise(mean_pc_CRPS_over_months=mean(CRPS*100))

CPRS_site<-predict_sites_plot$prediction_metrics%>%
  filter(site=="all")%>%
  summarise(mean_pc_CRPS_over_months=mean(CRPS*100))

## and quantify relative fit as with monthly predictions
(1-CPRS_site$mean_pc_CRPS_over_months/CPRS_site_null$mean_pc_CRPS_over_months)*100



print(predict_month_no_ANC$data_w_probs[1:10,1:10],row.names=F)
names(predict_month_no_ANC$data_w_probs)[4006]
check2<-months_to_predict_no_ANC$data_to_model

data_to_predict<-months_to_predict_no_ANC$simulated_survey_data%>%filter(ANC==0,month%in%months_to_predict_no_ANC$pred_months|site%in%months_to_predict_no_ANC$pred_sites)

predictions_null<-predict_month_no_ANC$data_w_probs%>%filter(ANC==0,month%in%months_to_predict_no_ANC$pred_months|site%in%months_to_predict_no_ANC$pred_sites)%>%
  select(month,site,starts_with("V"))

predictions_model<-predict_months$data_w_probs%>%filter(ANC==0,month%in%months_to_predict_no_ANC$pred_months|site%in%months_to_predict_no_ANC$pred_sites)%>%
  select(month,site,starts_with("V"))



merged_null<-merge(data_to_predict,predictions_null,by=c("month","site"))
merged_model<-merge(data_to_predict,predictions_model,by=c("month","site"))



null_prediction_summary<-get_metrics(data_to_predict,predictions_null)




check$merged_preds$CRPS

pred_cols_null<-grep("V", names(merged_null))
pred_cols_model<-grep("V", names(merged_model))
prediction_matrix_null<-as.matrix(merged_null[, pred_cols_null])
prediction_matrix_model<-as.matrix(merged_model[, pred_cols_model])

merged_null$CRPS<-sapply(
   seq_along(merged_null$positive),
   function(x){
     mean(crps_binom(y=merged_null$positive[x],size=merged_null$sample_size[x],prob=prediction_matrix_null[x,]))
   }
 )
 

merged_model$CRPS<-sapply(
   seq_along(merged_model$positive),
   function(x){
     mean(crps_binom(y=merged_model$positive[x],size=merged_model$sample_size[x],prob=prediction_matrix_model[x,]))
   }
 )
 
weighted_proportions_by_month <- merged_model %>%
  mutate(across(starts_with("V"), ~ . * sample_size)) %>%
  group_by(month) %>%
  summarise(
    across(starts_with("V"), sum, .names = "sum_{.col}"),
    sample_size = sum(sample_size),
    positive = sum(positive)
  ) %>%
  mutate(across(starts_with("sum_V"), ~ ./sample_size, .names = "weighted_{.col}"))

weighted_proportions_by_month_null <- merged_null %>%
  mutate(across(starts_with("V"), ~ . * sample_size)) %>%
  group_by(month) %>%
  summarise(
    across(starts_with("V"), sum, .names = "sum_{.col}"),
    sample_size = sum(sample_size),
    positive = sum(positive)
  ) %>%
  mutate(across(starts_with("sum_V"), ~ ./sample_size, .names = "weighted_{.col}"))


weighted_pred_cols<-grep("weighted_sum_V", names(weighted_proportions_by_month))

weighted_proportions_by_month$CRPS<-sapply(
  seq_along(weighted_proportions_by_month$positive),
  function(x){
    mean(crps_binom(y=weighted_proportions_by_month$positive[x],size=weighted_proportions_by_month$sample_size[x],prob=as.numeric(weighted_proportions_by_month[x,weighted_pred_cols])))
  }
)
weighted_pred_cols_null<-grep("weighted_sum_V", names(weighted_proportions_by_month_null))

weighted_proportions_by_month_null$CRPS<-sapply(
  seq_along(weighted_proportions_by_month_null$positive),
  function(x){
    mean(crps_binom(y=weighted_proportions_by_month_null$positive[x],size=weighted_proportions_by_month_null$sample_size[x],prob=as.numeric(weighted_proportions_by_month_null[x,weighted_pred_cols])))
  }
)

mean(weighted_proportions_by_month_null$CRPS)
mean(weighted_proportions_by_month$CRPS)
mean(weighted_proportions_by_month$positive)
merged_model<-
 seq_along(merged$positive[1:20]),
 function(x){
   mean(crps_binom(y=merged$positive[x],size=merged$sample_size[x],prob=as.numeric(merged[x, pred_cols])))
 }
 )
 mean(crps_binom(y=merged$positive[x],size=merged$sample_size[x],prob=merged[x, pred_cols]))

 check<-merged[2, pred_cols]
summary(check)
  pred_cols
apply(merged[,]

crps_binom(c(5,1,2),10,c(0.5,0.1,0.3))

crps_binom()
sites_to_predict_no_ANC<-sites_to_predict
sites_to_predict_no_ANC$data_to_model<-sites_to_predict$data_to_model%>%
  filter(ANC==0)
  
check<-months_to_predict$data_to_model


check_RT<-compare_RE_site(sites_to_predict_no_ANC$data_to_model,100,200,1)
predict_site_null<-get_fit_plots(check_RT,sites_to_predict_no_ANC$simulated_survey_data,sites_to_predict_no_ANC$param_df,pred_sites=sites_to_predict_no_ANC$pred_sites)
predict_site_null$site_plot
predict_months_plot<-get_fit_plots(predict_months,months_to_predict$simulated_survey_data,months_to_predict$param_df,pred_months=months_to_predict$pred_months)



data<-predict_months$data_w_probs
survey_data<-months_to_predict$simulated_survey_data
### get prevalence by month
prev_by_month <- survey_data %>%
  group_by(month) %>%
  summarise(observed_mean = sum(positive) / sum(sample_size),
            observed_lower = binom.confint(sum(positive), sum(sample_size), methods = "wilson")$lower,
            observed_upper = binom.confint(sum(positive), sum(sample_size), methods = "wilson")$upper) %>%
  mutate(Status = ifelse(month %in% pred_months, "Predicted", "Fitted")) %>%
  arrange(month) %>%
  mutate(change_in_month = c(1, diff(month) > 1),
         change_in_status = c(1, diff(as.numeric(as.factor(Status))) != 0),
         Segment = cumsum(change_in_month | change_in_status)) %>%
  select(-change_in_month, -change_in_status) 


## For each month want to site-specific weights - but if a censored use % for remaining data
## get % sampled by site outside of prediction months
site_weights_for_pred_months<-data%>%
  filter(ANC==0) %>%
  group_by(site) %>%
  summarise(total_sample_size = sum(sample_size)) %>%
  mutate(total_samples = sum(total_sample_size),
         overall_site_weight = total_sample_size / total_samples)
pred_months<-months_to_predict$pred_months
## get sample weights for  months with observed data 
data <- data %>%
  filter(ANC == 0) %>%
  group_by(month) %>%
  # First, compute the total samples per month
  mutate(total_sample_size = sum(sample_size)) %>%
  ungroup() %>%
  # Then calculate the site weight
  group_by(site, month) %>%
  mutate(monthly_site_weight = sample_size / total_sample_size) %>%
  ungroup() 


### combine overall site-specific weights for predicted months and monthly site-specific weights for observed
data_w_weights <- data %>%
  left_join(site_weights_for_pred_months %>% select(site, overall_site_weight), by = "site") %>%
  mutate(
    effective_month_weight = if_else(month %in% pred_months, overall_site_weight,monthly_site_weight)
  )
## get weighted predictions by month
fit_by_month<-data_w_weights%>%
  filter(ANC==0)%>%
  tidyr::pivot_longer(cols = starts_with("V"), names_to = "variable", values_to = "prediction") %>%
  mutate(
    weighted_prediction = prediction * effective_weight
  )%>%group_by(month, variable) %>%
  summarise(weighted_sum = sum(weighted_prediction), 
            total_weight = sum(effective_weight), .groups = "drop")%>%
  mutate(weighted_average = weighted_sum / total_weight)%>%
  select(month, variable, weighted_average)%>%
  group_by(month) %>%
  summarise(across(c(weighted_average), list(
    model_lower = ~quantile(.x, probs = 0.025),
    model_median = ~quantile(.x, probs = 0.50),
    model_upper = ~quantile(.x, probs = 0.975)
  )))
## merge prevalence data and weighted fits/predictions
prev_by_month <- merge(prev_by_month,fit_by_month,by="month")
names(prev_by_month) <- c("month", "observed_mean", "observed_lower", "observed_upper","Status","Segment","model_lower", "model_median", "model_upper")

## plot comparison
temporal_plot <- ggplot(prev_by_month, aes(x = month)) +
  geom_point(aes(y = observed_mean), color = "blue") +
  geom_errorbar(aes(ymin = observed_lower, ymax = observed_upper), width = 0.2, color = "blue") +
  geom_ribbon(aes(ymin = model_lower, ymax = model_upper, fill = Status, group = Segment), alpha = 0.5) +
  geom_line(aes(y = model_median, color = Status, group = Segment)) +
  scale_fill_manual(values = c("Predicted" = cols[1], "Fitted" = cols[2])) +
  scale_color_manual(values = c("Predicted" = cols[1], "Fitted" = cols[2])) +
  labs(x = "Month", y = "Prevalence", title = "Observed vs Modelled Prevalence by Month") +
  theme_minimal() +
  guides(fill = guide_legend(title = "Legend"), color = guide_legend(title = "Legend"))
temporal_plot

sites_to_predict<-generate_data_m1_runif_site()
predict_sites<-predict_sites_m1(sites_to_predict$data_to_model,100,200,1)
(predict_sites$data_w_probs%>%filter(ANC==0,site>16))[,1:10]
data<-predict_sites$data_w_probs
survey_data<-sites_to_predict$simulated_survey_data
pred_sites<-sites_to_predict$pred_sites
### get prevalence by site
prev_by_site <- survey_data %>%
  group_by(site) %>%
  summarise(observed_mean = sum(positive) / sum(sample_size),
            observed_lower = binom.confint(sum(positive), sum(sample_size), methods = "wilson")$lower,
            observed_upper = binom.confint(sum(positive), sum(sample_size), methods = "wilson")$upper)%>%
  mutate(Status = ifelse(site %in% pred_sites, "Predicted", "Fitted"))


## For each site want month-specific weights - but if a censored site use % for remaining data
## get % sampled by month outside of prediction sites
month_weights_for_pred_sites<-data%>%
  filter(ANC==0) %>%
  group_by(month) %>%
  summarise(total_sample_size = sum(sample_size)) %>%
  mutate(total_samples = sum(total_sample_size),
         overall_month_weight = total_sample_size / total_samples)

## get sample weights for  sites with observed data 
data <- data %>%
  filter(ANC == 0) %>%
  group_by(site) %>%
  # First, compute the total samples per site
  mutate(total_sample_size = sum(sample_size)) %>%
  ungroup() %>%
  # Then calculate the month weight
  group_by(month, site) %>%
  mutate(site_monthly_weight = sample_size / total_sample_size) %>%
  ungroup() 


### combine overall month-specific weights for predicted sites and site month-specific weights for observed
data_w_weights <- data %>%
  left_join(month_weights_for_pred_sites %>% select(month, overall_month_weight), by = "month") %>%
  mutate(
    effective_site_weight = if_else(site %in% pred_sites, overall_month_weight,site_monthly_weight)
  )

data_w_weights
## get weighted predictions by site
fit_by_site<-data_w_weights%>%
  filter(ANC==0)%>%
  tidyr::pivot_longer(cols = starts_with("V"), names_to = "variable", values_to = "prediction") %>%
  mutate(
    weighted_prediction = prediction * effective_site_weight
  )%>%group_by(site, variable) %>%
  summarise(weighted_sum = sum(weighted_prediction), 
            total_weight = sum(effective_site_weight), .groups = "drop")%>%
  mutate(weighted_average = weighted_sum / total_weight)%>%
  select(site, variable, weighted_average)%>%
  group_by(site) %>%
  summarise(across(c(weighted_average), list(
    model_lower = ~quantile(.x, probs = 0.025),
    model_median = ~quantile(.x, probs = 0.50),
    model_upper = ~quantile(.x, probs = 0.975)
  )))
## merge prevalence data and weighted fits/predictions
prev_by_site <- merge(prev_by_site,fit_by_site,by="site")
names(prev_by_site) <- c("month", "observed_mean", "observed_lower", "observed_upper","Status","model_lower", "model_median", "model_upper")

##make plot
site_plot <- ggplot(prev_by_site, aes(x = observed_mean, y = model_median,color=Status)) +
  geom_point() +
  geom_errorbar(aes(ymin = model_lower, ymax = model_upper), width = 0.01) +
  geom_errorbarh(aes(xmin = observed_lower, xmax = observed_upper), height = 0.01) +
  labs(x = "Observed Prevalence (Mean)", y = "Modeled Prevalence (Median)")+
  theme_minimal()+geom_abline()


site_plot


predictions_summary <- weighted_averages 
predictions_summary
m1_fitting$fit_array

#### USING MODELS TO RECONSTRUCT SURVEY DATA USING ANC
### Generate data with non-normal underlying prevalence by month
### default censors all data apart from a few months every two years
months_to_predict<-generate_data_m1_runif_month()
get_data_plots(months_to_predict$data_to_model)
check<-months_to_predict$data_to_model
## fit model with fixed effects by months
predict_months<-predict_months_m1(months_to_predict$data_to_model,100,200,1)
check<-months_to_predict$data_to_model%>%filter(ANC==0)
get_fit_plots(predict_months,)

site_weights<-check%>%
  filter(
    ANC==0,
    !month %in% months_to_predict$pred_months) %>%
  group_by(site) %>%
  summarise(total_sample_size = sum(sample_size), .groups = "drop") %>%
  ungroup() %>%
  mutate(total_samples = sum(total_sample_size),
         weight = total_sample_size / total_samples)
monthly_weights <- check %>%
  group_by(month) %>%
  summarise(monthly_sample_size = sum(sample_size), .groups = "drop")

check <- check %>%
  left_join(site_weights %>% select(site, weight), by = "site") %>%
  left_join(monthly_weights, by = "month")

check <- check %>%
  mutate(
    effective_weight = if_else(month %in% months_to_predict$pred_months, weight, sample_size / monthly_sample_size)
  )
check
## should now see predictions for months as well as those included in the fitting
predict_months_plot<-get_fit_plots(predict_months,months_to_predict$simulated_survey_data,months_to_predict$param_df,pred_months=months_to_predict$pred_months)
  predict_months_plot

check<-(predict_months$data_w_probs)
dim(m1_fitting$data_w_probs)
  ### Generate data with non-normal underlying prevalence by site
### default censors sites 15-20
sites_to_predict<-generate_data_m1_runif_site()
## fit model with fixed effects by months
predict_sites<-predict_sites_m1(sites_to_predict$data_to_model,100,200,1)
## should now see predictions for months as well as those included in the fitting
predict_sites_plot<-get_plots(predict_sites,sites_to_predict$simulated_survey_data,sites_to_predict$param_df,pred_sites=sites_to_predict$pred_sites)
predict_sites_plot




complex_fitting$DIC
complex_fitting$p_d

simple_data<-generate_data_simple()


simple_data$data_to_model
simple_data$
simple_fitting<-run_greta_preg_simple(simple_data$data_to_model,100,200,1)
complex_fitting<-run_greta_preg_complex(complex_data$data_to_model,100,200,1)
simple_fitting_complex_data<-run_greta_preg_simple(complex_data$data_to_model,100,200,1)

simple_fitting_complex_data_plot<-get_plots(simple_fitting_complex_data,complex_data$simulated_survey_data,complex_data$param_df)





predict_temp_data<-run_greta_predict_month(temporal_data_to_predict$data_to_model,100,200,1)

site_data_to_predict<-generate_data_simple_FE_site()
check<-site_data_to_predict$data_to_model
predict_spatial_data<-run_greta_predict_site(site_data_to_predict$data_to_model,1000,2000,1)
check<-site_data_to_predict$data_to_model
checksite_data_to_predict$pred_sites

check<-site_data_to_predict$data_to_model


mcmc_intervals(predict_spatial_data$draws)

simple_fitting_complex_data_plot
complex_plots
mcmc_intervals(simple_fitting$draws)
complex_plots
plots$temporal_plot
simple_plots$spatial_plot
dim(complex_fitting$fit_array)
mcmc_intervals(complex_fitting$draws)
rbinom(4, size = 1000, prob = c(0.1,0.2,0.3,0.4))
complex_fitting$simulated_survey_data
simple_fitting$
  
  prev_site<-complex_data$data_to_model%>%group_by(site,ANC)%>%
  summarise(prev=sum(positive)/sum(sample_size))%>%
  pivot_wider(names_from = ANC, values_from = prev, names_prefix = "ANC_")

ggplot(prev_site, aes(x = ANC_0, y = ANC_1)) +
  geom_point() +  # Add points
  geom_text(aes(label = site), vjust = -1) +  # Add site labels
  labs(x = "Prevalence when ANC=0", y = "Prevalence when ANC=1", title = "Site-specific Prevalence Comparison") +
  theme_minimal() +  # Use a minimal theme
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") 
simple_data$param_df